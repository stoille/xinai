{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis for xᵢⁿAI Research Toolkit\n",
    "\n",
    "This notebook provides an initial exploration of the data and model behavior for our AI Interpretability research project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"xᵢⁿai - Exploratory Analysis\").getOrCreate()\n",
    "\n",
    "# Load the data\n",
    "df = spark.read.csv(\"../data/raw/sample_data.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"tf\")\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, cv, idf])\n",
    "model = pipeline.fit(df)\n",
    "processed_df = model.transform(df)\n",
    "\n",
    "processed_df.select(\"text\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas for easier visualization\n",
    "pandas_df = processed_df.toPandas()\n",
    "\n",
    "# Plot label distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='label', data=pandas_df)\n",
    "plt.title('Label Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Prepare a sample input\n",
    "sample_text = pandas_df['text'].iloc[0]\n",
    "inputs = tokenizer(sample_text, return_tensors=\"pt\")\n",
    "\n",
    "# Get model prediction\n",
    "outputs = model(**inputs)\n",
    "prediction = torch.argmax(outputs.logits).item()\n",
    "print(f\"Sample text: {sample_text}\")\n",
    "print(f\"Predicted label: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the model's decision\n",
    "ig = IntegratedGradients(model)\n",
    "attributions, delta = ig.attribute(inputs['input_ids'], target=prediction, return_convergence_delta=True)\n",
    "\n",
    "# Visualize attributions\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "attr_scores = attributions.sum(dim=-1).squeeze(0)\n",
    "attr_scores = attr_scores / torch.norm(attr_scores)\n",
    "attr_scores = attr_scores.cpu().detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "sns.barplot(x=tokens, y=attr_scores)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Token Attributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides an initial exploration of our data and model behavior. We've seen how the data is distributed, how our model makes predictions, and how we can interpret these predictions using integrated gradients. Further analysis could involve:\n",
    "\n",
    "1. Exploring model drift over time\n",
    "2. Analyzing attention patterns in different layers of the model\n",
    "3. Investigating how different preprocessing steps affect model interpretability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
